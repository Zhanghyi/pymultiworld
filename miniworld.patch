diff --git a/torch/csrc/distributed/c10d/ProcessGroupGloo.cpp b/torch/csrc/distributed/c10d/ProcessGroupGloo.cpp
index d3c9a612c46..3624fe18b04 100644
--- a/torch/csrc/distributed/c10d/ProcessGroupGloo.cpp
+++ b/torch/csrc/distributed/c10d/ProcessGroupGloo.cpp
@@ -763,10 +763,12 @@ ProcessGroupGloo::ProcessGroupGloo(
       options_(options),
       stop_(false),
       collectiveCounter_(0) {
+  std::cout << ">>> 1" << std::endl;
   auto& devices = options->devices;
   if (devices.empty()) {
     TORCH_CHECK(false, "No device(s) specified");
   }
+  std::cout << ">>> 2" << std::endl;
 
   // Create and connect a context for every device.
   //
@@ -781,33 +783,43 @@ ProcessGroupGloo::ProcessGroupGloo(
   // by a single I/O thread.
   //
   contexts_.reserve(options->devices.size());
+  std::cout << ">>> 3" << std::endl;
   for (const auto i : c10::irange(options->devices.size())) {
+    std::cout << ">>> 4 index: " << i << std::endl;
     auto context = std::make_shared<::gloo::rendezvous::Context>(rank_, size_);
+    std::cout << ">>> 5 index: " << i << std::endl;
     auto store = ::gloo::rendezvous::PrefixStore(std::to_string(i), *store_);
     context->setTimeout(options->timeout);
+    std::cout << ">>> 6 index: " << i << std::endl;
     try {
       context->connectFullMesh(store, options->devices[i]);
+      std::cout << ">>> 7 index: " << i << std::endl;
     } catch (const std::runtime_error& e) {
       auto err = e.what();
       // TORCH_CHECK to print the cpp stacktrace.
       auto msg = c10::str("Gloo connectFullMesh failed with ", err);
       logAndThrow(msg, msg);
     }
+    std::cout << ">>> 8 index: " << i << std::endl;
     contexts_.push_back(std::move(context));
+    std::cout << ">>> 9 index: " << i << std::endl;
   }
-
+  std::cout << ">>> 10" << std::endl;
   // Every worker thread stores the AsyncWork object it's currently
   // working on in the workInProgress_ vector. It must have size equal
   // to the number of workers such that they can simply index into it
   // using the worker index they are started with.
   workInProgress_.resize(options->threads);
-
+  std::cout << ">>> 11" << std::endl;
   threads_.resize(options->threads);
   for (const auto i : c10::irange(threads_.size())) {
+    std::cout << ">>> 12 thread " << i << std::endl;
     threads_[i] = std::thread(&ProcessGroupGloo::runLoop, this, i);
+    std::cout << ">>> 13 thread " << i << std::endl;
   }
-
+  std::cout << ">>> 14" << std::endl;
   init();
+  std::cout << ">>> 15" << std::endl;
 }
 
 ProcessGroupGloo::~ProcessGroupGloo() {
diff --git a/torch/distributed/__init__.py b/torch/distributed/__init__.py
index 5fb05a34771..871f7a25526 100644
--- a/torch/distributed/__init__.py
+++ b/torch/distributed/__init__.py
@@ -108,6 +108,17 @@ if is_available():
         _coalescing_manager,
         _CoalescingManager,
         _get_process_group_name,
+        # MLEE: for miniworld
+        GroupMember,
+        _backend,
+        _group_count,
+        _pg_backend_config,
+        _pg_group_ranks,
+        _pg_map,
+        _pg_names,
+        _rank_not_in_group,
+        _world,
+        _World,
     )
 
     from .rendezvous import (
